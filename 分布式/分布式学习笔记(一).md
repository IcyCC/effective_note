<!--
 * @Author: your name
 * @Date: 2020-05-30 12:04:31
 * @LastEditTime: 2020-05-30 17:39:40
 * @LastEditors: Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: /code_note/分布式/GFS.md
--> 

# 分布式学习

本文是对 MIT6.824的一个笔记 标注出要看的 paper 和对 paper 的一个简单描述. 用作个人复习和简单知道要讲啥,带着内容去听课.

## MapReduce

此论文比较好理解 略. 

## GFS

> The Google File System  https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/gfs-sosp2003.pdf

### 架构

![](https://gitee.com/IcyCC/PicHouse/raw/master/assests/20200530152755.png)

master 存放 元数据:

1. 文件名和 chunk 对应
2. chunk 和 chunk servers 的 的对应

chunk server 存放:

1. chunk 的 偏移
2. 具体的 chunk

### 发现数据异常

chunk 由 block 组成 一个block 64kb

block 保存 32bit 的校验和 检查校验和.

### 减少 chunk 挂掉的损失

复制 chunk 放三个地方, 2+1

### 恢复 chunk

损坏的 cs 向 mster 求助, 找别的 cs 求助

### cs 挂点

* 用心跳检测
* 排工作列表 优先修复最紧急的

### 读文件

![](https://gitee.com/IcyCC/PicHouse/raw/master/assests/20200530152300.png)

1. clint 问 master 在哪里 (filename, chunkid[可用偏移计算])
2. master 告诉 client 在哪里(cs)
3. client 读 cs (chunkid,offset)
4. cs 返回数据 

### 写文件

![](https://gitee.com/IcyCC/PicHouse/raw/master/assests/20200530152700.png)

1. client 向 master 要所有副本cs
2. master 告诉 client 副本 cs
3. client 向 cs 发送数据
4. cs 之间数据同步, 给 client 响应
5. client 向primary cs 发送写请求
6. 由 primary cs 负责管理别人写
7. 完成后给 client 响应

出错了让客户端重试

## 主从备份

>  The Design of a
> Practical System for
> Fault-Tolerant Virtual Machines https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf

主要实现有两种:

1. state transfer 状态转义:

主节点发送新的状态给从节点

2. replicated state machine 备份状态机:

主节点客户端执行的操作 发送给备份节点.
要求: 在相同的其实状态,相同的操作, 相同的顺序, 确定的, 到相同的结束状态


state transfer 简单, 但是流量大

replicated state machine 流量少, 但是复杂

思考的问题:

* 那些状态要同步?
* 主节点是否需要等从节点同步?
* 什么时间切换?
* 怎么提高切换速度?

而在 Fault-Tolerant Virtual Machines 论文中, 目标是备用机代替主机后,客户端感受不到这个切换. 

状态转义就是 x86指令的转转移

由于主备机存在延迟, 所以存在如下情况:

主机操作 [a,b,c,out] 此时主机已经执行out了, 而备机只是收到了a,b, 如果此时挂掉, 那么 c 就没执行完,且因为客户端已经收到 out 的结果,对此并不知情, 就出现了不一致.

为了解决这个问题, 论文提出了输出要求. 
即 到了输出指令不输出, 知道确认备机收完全部指令再输出. 但是这样不能避免客户端会看到两次输出, 而在论文里认为这样是可以接受的,应用会处理.

对于脑裂问题, 即主备机互相因为网络故障,无法通讯,都认为自己主节点, 论文提出了共享一个虚拟磁盘,然后往磁盘里写 test-and-set 锁, 谁不能访问这个磁盘谁就算挂了.






